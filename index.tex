% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={clase 22 de agosto 2023},
  pdfauthor={Susana Hernández},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{clase 22 de agosto 2023}
\author{Susana Hernández}
\date{Invalid Date}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[sharp corners, boxrule=0pt, frame hidden, breakable, interior hidden, borderline west={3pt}{0pt}{shadecolor}, enhanced]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

This is a Quarto book.

To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\bookmarksetup{startatroot}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

This is a book created from markdown and executable code.

See Knuth (1984) for additional discussion of literate programming.

\bookmarksetup{startatroot}

\hypertarget{summary}{%
\chapter{Summary}\label{summary}}

In summary, this book has no content whatsoever.

\bookmarksetup{startatroot}

\hypertarget{tarea-1}{%
\chapter{Tarea 1}\label{tarea-1}}

\begin{codelisting}

\caption{\texttt{Exploring functions to generate random variables with a Bernoulli distribution.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ bernoulli}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\NormalTok{fig\_01, ax\_01 }\OperatorTok{=}\NormalTok{ plt.subplots(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{fig\_02, ax\_02 }\OperatorTok{=}\NormalTok{ plt.subplots(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{p }\OperatorTok{=} \FloatTok{0.3}
\NormalTok{mean, var, skew, kurt }\OperatorTok{=}\NormalTok{ bernoulli.stats(p, moments}\OperatorTok{=}\StringTok{\textquotesingle{}mvsk\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(mean, var, skew,kurt)}

\NormalTok{x }\OperatorTok{=}\NormalTok{ np.arange(bernoulli.ppf(}\FloatTok{0.01}\NormalTok{, p),}
\NormalTok{              bernoulli.ppf(}\FloatTok{0.99}\NormalTok{, p))}
\NormalTok{ax\_01.plot(x, bernoulli.pmf(x, p), }\StringTok{\textquotesingle{}bo\textquotesingle{}}\NormalTok{, ms}\OperatorTok{=}\DecValTok{8}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}bernoulli pmf\textquotesingle{}}\NormalTok{)}
\NormalTok{ax\_01.vlines(x, }\DecValTok{0}\NormalTok{, bernoulli.pmf(x, p), colors}\OperatorTok{=}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, lw}\OperatorTok{=}\DecValTok{5}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.5}\NormalTok{)}
\NormalTok{r }\OperatorTok{=}\NormalTok{ bernoulli.rvs(p, size}\OperatorTok{=}\DecValTok{1000}\NormalTok{)}
\NormalTok{ax\_02.hist(r, bins}\OperatorTok{=}\DecValTok{200}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\includegraphics{figura1.png} \includegraphics{F2.png}

\begin{codelisting}

\caption{\texttt{Exploring functions to generate random variables with a Gaussian distribution.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ norm}

\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{mean, var, skew, kurt }\OperatorTok{=}\NormalTok{ norm.stats(moments}\OperatorTok{=}\StringTok{\textquotesingle{}mvsk\textquotesingle{}}\NormalTok{)}

\NormalTok{x }\OperatorTok{=}\NormalTok{ np.linspace(norm.ppf(}\FloatTok{0.01}\NormalTok{), norm.ppf(}\FloatTok{0.99}\NormalTok{), }\DecValTok{100}\NormalTok{)}
\NormalTok{ax.plot(}
\NormalTok{    x,}
\NormalTok{    norm.pdf(x),}
    \StringTok{\textquotesingle{}r{-}\textquotesingle{}}\NormalTok{,}
\NormalTok{    lw}\OperatorTok{=}\DecValTok{5}\NormalTok{,}
\NormalTok{    alpha}\OperatorTok{=}\FloatTok{0.6}\NormalTok{,}
\NormalTok{    label}\OperatorTok{=}\StringTok{\textquotesingle{}norm pdf\textquotesingle{}}
\NormalTok{)}
\NormalTok{rv }\OperatorTok{=}\NormalTok{ norm()}
\NormalTok{ax.plot(x, rv.pdf(x), }\StringTok{\textquotesingle{}k{-}\textquotesingle{}}\NormalTok{, lw}\OperatorTok{=}\DecValTok{2}\NormalTok{, label}\OperatorTok{=}\StringTok{\textquotesingle{}frozen pdf\textquotesingle{}}\NormalTok{)}
\NormalTok{vals }\OperatorTok{=}\NormalTok{ norm.ppf([}\FloatTok{0.001}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.999}\NormalTok{])}

\NormalTok{np.allclose([}\FloatTok{0.001}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.999}\NormalTok{], norm.cdf(vals))}

\NormalTok{r }\OperatorTok{=}\NormalTok{ norm.rvs(size}\OperatorTok{=}\DecValTok{50000}\NormalTok{)}

\NormalTok{ax.hist(r, density}\OperatorTok{=}\VariableTok{True}\NormalTok{, bins}\OperatorTok{=}\StringTok{\textquotesingle{}auto\textquotesingle{}}\NormalTok{, histtype}\OperatorTok{=}\StringTok{\textquotesingle{}stepfilled\textquotesingle{}}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.2}\NormalTok{)}
\NormalTok{ax.set\_xlim([x[}\DecValTok{0}\NormalTok{], x[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]])}
\NormalTok{ax.legend(loc}\OperatorTok{=}\StringTok{\textquotesingle{}best\textquotesingle{}}\NormalTok{, frameon}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{figure}

{\centering \includegraphics{Figure_3.png}

}

\caption{Figura 3}

\end{figure}

\begin{codelisting}

\caption{\texttt{Revising multivariate Gaussian.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{from}\NormalTok{ mpl\_toolkits.mplot3d }\ImportTok{import}\NormalTok{ axes3d}
\ImportTok{from}\NormalTok{ scipy.stats }\ImportTok{import}\NormalTok{ multivariate\_normal}

\NormalTok{x }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{100}\NormalTok{, endpoint}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{y }\OperatorTok{=}\NormalTok{ multivariate\_normal.pdf(x, mean}\OperatorTok{=}\FloatTok{2.5}\NormalTok{, cov}\OperatorTok{=}\FloatTok{0.5}\NormalTok{)}\OperatorTok{;}

\NormalTok{fig1 }\OperatorTok{=}\NormalTok{ plt.figure()}
\NormalTok{ax }\OperatorTok{=}\NormalTok{ fig1.add\_subplot(}\DecValTok{111}\NormalTok{)}
\NormalTok{ax.plot(x, y)}
\CommentTok{\# plt.show()}

\NormalTok{x, y }\OperatorTok{=}\NormalTok{ np.mgrid[}\OperatorTok{{-}}\DecValTok{5}\NormalTok{:}\DecValTok{5}\NormalTok{:}\FloatTok{.1}\NormalTok{, }\OperatorTok{{-}}\DecValTok{5}\NormalTok{:}\DecValTok{5}\NormalTok{:}\FloatTok{.1}\NormalTok{]}
\NormalTok{pos }\OperatorTok{=}\NormalTok{ np.dstack((x, y))}
\NormalTok{rv }\OperatorTok{=}\NormalTok{ multivariate\_normal([}\FloatTok{0.5}\NormalTok{, }\OperatorTok{{-}}\FloatTok{0.2}\NormalTok{], [[}\FloatTok{2.0}\NormalTok{, }\FloatTok{0.3}\NormalTok{], [}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.5}\NormalTok{]])}
\NormalTok{fig2 }\OperatorTok{=}\NormalTok{ plt.figure()}
\NormalTok{ax2 }\OperatorTok{=}\NormalTok{ fig2.add\_subplot(}\DecValTok{111}\NormalTok{)}
\NormalTok{ax2.contourf(x, y, rv.pdf(pos))}
\CommentTok{\# plt.show()}

\NormalTok{ax }\OperatorTok{=}\NormalTok{ plt.figure().add\_subplot(projection}\OperatorTok{=}\StringTok{\textquotesingle{}3d\textquotesingle{}}\NormalTok{)}
\NormalTok{ax.plot\_surface(}
\NormalTok{    x,}
\NormalTok{    y,}
\NormalTok{    rv.pdf(pos),}
\NormalTok{    edgecolor}\OperatorTok{=}\StringTok{\textquotesingle{}royalblue\textquotesingle{}}\NormalTok{,}
\NormalTok{    lw}\OperatorTok{=}\FloatTok{0.5}\NormalTok{,}
\NormalTok{    rstride}\OperatorTok{=}\DecValTok{8}\NormalTok{,}
\NormalTok{    cstride}\OperatorTok{=}\DecValTok{8}\NormalTok{,}
\NormalTok{    alpha}\OperatorTok{=}\FloatTok{0.4}
\NormalTok{)}
\NormalTok{ax.contour(x, y, rv.pdf(pos), zdir}\OperatorTok{=}\StringTok{\textquotesingle{}z\textquotesingle{}}\NormalTok{, offset}\OperatorTok{={-}}\FloatTok{.2}\NormalTok{, cmap}\OperatorTok{=}\StringTok{\textquotesingle{}coolwarm\textquotesingle{}}\NormalTok{)}
\NormalTok{ax.contour(x, y, rv.pdf(pos), zdir}\OperatorTok{=}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{, offset}\OperatorTok{={-}}\DecValTok{5}\NormalTok{, cmap}\OperatorTok{=}\StringTok{\textquotesingle{}coolwarm\textquotesingle{}}\NormalTok{)}
\NormalTok{ax.contour(x, y, rv.pdf(pos), zdir}\OperatorTok{=}\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{, offset}\OperatorTok{=}\DecValTok{5}\NormalTok{, cmap}\OperatorTok{=}\StringTok{\textquotesingle{}coolwarm\textquotesingle{}}\NormalTok{)}

\NormalTok{ax.}\BuiltInTok{set}\NormalTok{(}
\NormalTok{    xlim}\OperatorTok{=}\NormalTok{(}\OperatorTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{),}
\NormalTok{    ylim}\OperatorTok{=}\NormalTok{(}\OperatorTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{),}
\NormalTok{    zlim}\OperatorTok{=}\NormalTok{(}\OperatorTok{{-}}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.2}\NormalTok{),}
\NormalTok{    xlabel}\OperatorTok{=}\StringTok{\textquotesingle{}X\textquotesingle{}}\NormalTok{,}
\NormalTok{    ylabel}\OperatorTok{=}\StringTok{\textquotesingle{}Y\textquotesingle{}}\NormalTok{,}
\NormalTok{    zlabel}\OperatorTok{=}\StringTok{\textquotesingle{}Z\textquotesingle{}}
\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\includegraphics{Figure_4.png} \includegraphics{Figure_5.png}
\includegraphics{Figure_6.png}

\bookmarksetup{startatroot}

\hypertarget{tarea-2}{%
\chapter{Tarea 2}\label{tarea-2}}

\newtheorem{demos}{Solución}
\newtheorem{teor}{Ejercicio}

Sea \(Y_{\delta,h}(t)\) una caminata aleatoria. Demuestre que para
\(\delta\) y \(h\) pequeño tenemos

\[
E\exp[i\lambda Y_{\delta,h}(t)]\thickapprox\exp\left[-\frac{t\lambda^{2}h^{2}}{2\delta}-\frac{t\lambda^{4}h^{4}}{12\delta}\right]
\]

Considere una caminata aleatoria que comienza en 0 con saltos \(h\) y
\(-h\) igualmente probables en los momentos \(\delta\), 2
\(\delta\),\(\dots\), donde \(h\) y \(\delta\) son números positivos.
Más precisamente, sea \(\{X_{n}\}_{n=1}^{\infty}\) una sucesión de
elementos aleatorios independientes e idénticamente distribuidos.
variables con \[
P\left[X_{i}=h\right]=P\left[X_{i}=-h\right]=\dfrac{1}{2},\forall i,
\]

Sea \(Y_{\delta,h}(0)=0\) y pongamos \[
Y_{\delta,h}(n\delta)=X_{1}+X_{2}+\cdots+X_{n}.
\]

Para \(t>0\), defina \(Y_{\delta,h}(t)\) mediante linealización, es
decir, para \(n\delta<t<(n + 1)\delta\), defina \[
Y_{\delta,h}(t)=\frac{(n+1)\delta-t}{\delta}Y_{\delta,h}(n\delta)+\frac{t-n\delta}{\delta}Y_{\delta,h}((n+1)\delta).
\]

Calculemos la función característica de \(Y_{\delta,h}(t)\), donde
\(\lambda\in\mathbb{R}\) fijo y sea \(t=n\delta\) así, \(n=t/\delta\).
Entonces se tiene que

\begin{eqnarray}\label{1}
    E\exp\left[i\lambda Y_{n,\delta}\left(t\right)\right] & = & \prod_{j=1}^{n}Ee^{i\lambda X_{j}},\text{ por ser variables independientes,}\nonumber\\
    & = & (Ee^{i\lambda X_{j}})^{n},\text{ por ser idénticamente distribuidas,}\nonumber\\
    & = & \frac{1}{2}(e^{i\lambda h}+e^{-i\lambda h})^{n},\nonumber\\
    & = & (\cos(\lambda h))^{n},\nonumber\\
    & = & (\cos(\lambda h))^{t/\delta},
\end{eqnarray}

Por otro lado, sea
\(u=\left[\cos\left(\lambda h\right)\right]^{1/\delta}\Rightarrow\ln\left(u\right)=\dfrac{1}{\delta}\ln\left[\cos\left(\lambda h\right)\right]\).

Usando la expansión de Taylor de \(\cos\left(x\right)\) se tiene que \[
\cos\left(\lambda h\right)\approx1-\dfrac{\left(\lambda h\right)^{2}}{2!}+\dfrac{\left(\lambda h\right)^{4}}{4!},
\]

entonces \begin{eqnarray}
    \ln\left(\cos\left(\lambda h\right)\right) & \approx & \ln\left[1-\dfrac{\left(\lambda h\right)^{2}}{2}+\dfrac{\left(\lambda h\right)^{4}}{4!}\right]\nonumber\\
 & \approx & -\dfrac{\left(\lambda h\right)^{2}}{2!}+\dfrac{\left(\lambda h\right)^{4}}{4!}-\frac{1}{2}\left(-\frac{\lambda^{2}h^{2}}{2!}+\frac{\lambda^{4}h^{4}}{4!}\right)^{2}\nonumber\\
  & = & -\dfrac{\lambda^{2} h^{2}}{2!}+\dfrac{\lambda ^{4}h^{4}}{4!}-\frac{1}{2}\left(\frac{\lambda^{4}h^{4}}{4}-\frac{\lambda^{6}h^{6}}{24^{2}}+\frac{\lambda^{8}h^{8}}{24}\right)\nonumber\\
   & = & -\dfrac{\lambda^{2} h^{2}}{2}+\dfrac{\lambda^{4} h^{4}}{24}-\frac{\lambda^{4}h^{4}}{8}-\frac{\lambda^{6}h^{6}}{(2)24^{2}}+\frac{\lambda^{8}h^{8}}{48}\nonumber\\
   & = & -\dfrac{\lambda^{2} h^{2}}{2}-\dfrac{\lambda^{4} h^{4}}{12}-\frac{\lambda^{6}h^{6}}{(2)24^{2}}+\frac{\lambda^{8}h^{8}}{48}
\end{eqnarray} para una \(h\) pequeña, se satisface que, \[
-\frac{\lambda^{6}h^{6}}{(2)24^{2}}+\frac{\lambda^{8}h^{8}}{48}\approx 0
\]

Por lo tanto,
\(\ln\left(\cos\left(\lambda h\right)\right)\approx -\dfrac{\lambda^{2} h^{2}}{2}-\dfrac{\lambda^{4} h^{4}}{12}\).\textbackslash{}
Así, para \(\delta\) y \(h\) pequeña, se tiene que
\(\ln u\approx \dfrac{1}{\delta}\left(-\dfrac{\lambda^{2} h^{2}}{2}-\dfrac{\lambda^{4} h^{4}}{12}\right)\).\textbackslash{}
Entonces

\begin{equation}
    u\approx\exp\left[\dfrac{1}{\delta}\left(-\dfrac{\lambda^{2} h^{2}}{2}-\dfrac{\lambda^{4} h^{4}}{12}\right)\right]
\end{equation}

Entonces por la ecuación (\ref{1}) \begin{equation}
    E\exp\left[i\lambda Y_{n,\delta}\left(t\right)\right]\approx\exp\left[-\dfrac{t\lambda^{2} h^{2}}{2\delta}-\dfrac{t\lambda^{4} h^{4}}{12\delta}\right]
\end{equation}

Calculando el limite \[
\lim_{\delta\to0}E\left[\exp\left(i\lambda Y_{n,\delta}\left(t\right)\right)\right]=\lim_{\delta\to0}\exp\left[-t\left(\left[\dfrac{h^{2}}{\delta}\right]\left(\dfrac{\lambda^{2}}{2}-\dfrac{\lambda^{4}h^{2}}{24}\right)\right)\right],
\]

Asumamos que \(\delta\to0\), \(h\to0\) pero \(h^{2}/\delta\to\infty\).
Entonces \(\lim_{\delta\to0} Y_{\delta, h}(t)\) no existe. Por otro
lado, consideremos la siguiente renormalización,

\begin{eqnarray}
    E\exp\left[i\lambda Y_{n,\delta}\left(t\right)+\dfrac{th^{2}\lambda^{2}}{2\delta}\right] & = & E\left[\exp (i\lambda Y_{n,\delta}\left(t\right))\exp\left(\dfrac{th^{2}\lambda^{2}}{2\delta}\right)\right]\nonumber\\
    & = & \exp\left(\dfrac{th^{2}\lambda^{2}}{2\delta}\right)E\exp\left[ i\lambda Y_{n,\delta}\left(t\right)\right]\nonumber\\
    & \approx & \exp\left(\dfrac{th^{2}\lambda^{2}}{2\delta}\right)\exp\left[-\dfrac{t\lambda^{2} h^{2}}{2\delta}-\dfrac{t\lambda^{4} h^{4}}{12\delta}\right]\nonumber\\
    & = & \exp\left(-\dfrac{t\lambda^{4} h^{4}}{12\delta}\right)
\end{eqnarray}

Así, si \(\delta,h\to0\) de tal manera que \(h^{2}/\delta\to\infty\) y
\(h^{4}/\delta\to0\), entonces \[
\lim_{\delta\to0}E\left[\exp\left(i\lambda Y_{n,\delta}\left(t\right)+\dfrac{th^{2}\lambda^{2}}{2}\right)\right]=\lim_{\delta\to0}\exp\left(\dfrac{\left(\lambda h\right)^{4}}{24\delta}\right)=1
\]

\bookmarksetup{startatroot}

\hypertarget{tarea-3}{%
\chapter{Tarea 3}\label{tarea-3}}

\newtheorem{demos}{Solución}

Si \(X\thicksim N(\mu,\sigma)\) entonces
\(\left(\dfrac{X-\mu}{\sigma}\right)\thicksim N(0,1)\).

Calculemos la función característica de la variable
\(\dfrac{X-\mu}{\sigma}\), \begin{eqnarray}\label{1.1}
\varphi_{\frac{X-\mu}{\sigma}}(t) & = & E\left[e^{it\left(\frac{X-\mu}{\sigma}\right)}\right]\nonumber\\
& = & E\left[e^{\left(\frac{itX}{\sigma}-\frac{it\mu}{\sigma}\right)}\right]\nonumber\\
& = & e^{-\frac{it\mu}{\sigma}}E\left[e^{\left(\frac{itX}{\sigma}\right)}\right]\nonumber\\
& = & e^{-\frac{it\mu}{\sigma}}\int_{-\infty}^{\infty}e^{\frac{itx}{\sigma}}\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}dx\nonumber\\
& = & e^{-\frac{it\mu}{\sigma}}\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{\frac{itx}{\sigma}}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}dx\nonumber\\
& = & e^{-\frac{it\mu}{\sigma}}\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{\frac{itx}{\sigma}-\frac{(x-\mu)^{2}}{2\sigma^{2}}}dx\nonumber\\
& = & e^{-\frac{it\mu}{\sigma}}\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{1}{2}\frac{(x-\mu)^{2}-2itx\sigma}{\sigma^{2}}}dx
\end{eqnarray} Observemos que, \begin{eqnarray}\label{1.2}
\frac{(x-\mu)^{2}-2itx\sigma}{\sigma^{2}} & = & \frac{x^{2}-2x\mu+\mu^{2}-2itx\sigma}{\sigma^{2}}\nonumber\\
& = & \frac{x^{2}}{\sigma^{2}}-\frac{2x\mu}{\sigma^{2}}+\frac{\mu^{2}}{\sigma^{2}}-\frac{2itx\sigma}{\sigma^{2}}\nonumber\\
& = & \frac{x^{2}}{\sigma^{2}}-\frac{2x}{\sigma}\left(\frac{\mu+it\sigma}{\sigma^{2}}\right)+\frac{\mu^{2}}{\sigma^{2}}\nonumber\\
& = & \left(\frac{x}{\sigma}-\left(\frac{\mu+it\sigma}{\sigma}\right)\right)^{2}-\left(\frac{\mu+it\sigma}{\sigma}\right)^{2}+\frac{\mu^{2}}{\sigma^{2}}\nonumber\\
& = & \left(\frac{x}{\sigma}-\left(\frac{\mu+it\sigma}{\sigma}\right)\right)^{2}-\frac{2 it\sigma\mu}{\sigma^{2}}-\frac{(it\sigma)^{2}}{\sigma^{2}}\nonumber\\
& = & \left(\frac{x}{\sigma}-\left(\frac{\mu+it\sigma}{\sigma}\right)\right)^{2}-\frac{2 it\mu}{\sigma}+t^{2}.
\end{eqnarray}

Sustituyendo (\ref{1.2}) en (\ref{1.1}), resulta

\begin{eqnarray}\label{1.3}
\varphi_{\frac{X-\mu}{\sigma}}(t) & = & e^{-\frac{it\mu}{\sigma}}\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{1}{2}\left[\left(\frac{x}{\sigma}-\left(\frac{\mu+it\sigma}{\sigma}\right)\right)^{2}-\frac{2 it\mu}{\sigma}+t^{2}\right]}dx\nonumber\\
& = & e^{-\frac{it\mu}{\sigma}}e^{\frac{it\mu}{\sigma}-\frac{t^{2}}{2}}\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{1}{2}\left(\frac{x}{\sigma}-\left(\frac{\mu+it\sigma}{\sigma}\right)\right)^{2}}dx\nonumber\\
& = & e^{-\frac{t^{2}}{2}}\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{1}{2}\left(\frac{x}{\sigma}-\left(\frac{\mu+it\sigma}{\sigma}\right)\right)^{2}}dx
\end{eqnarray}

Sea
\(u=\frac{x}{\sigma}-\left(\frac{\mu+it\sigma}{\sigma}\right)\Longrightarrow du=\frac{1}{\sigma}dx\),
sustituyendo esto en (\ref{1.3}), resulta \begin{equation}\label{1.4}
\varphi_{\frac{X-\mu}{\sigma}}(t) = e^{-\frac{t^{2}}{2}}\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{u^{2}}{2}}du
\end{equation}

de aquí se sigue que \(u\thicksim N(0,1)\), entonces \[
\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{u^{2}}{2}}dx=1.
\] sustituyendo esto ultimo en (\ref{1.4}), se tiene,

\begin{equation}\label{1.5}
\varphi_{\frac{X-\mu}{\sigma}}(t) =e^{-\frac{t^{2}}{2}},
\end{equation} Por otro lado, consideremos \(Z\thicksim N(0,1)\),
entonces \begin{equation*}
\varphi_{Z}(t) =e^{-\frac{t^{2}}{2}}.
\end{equation*}

Entonces \(\varphi_{Z}(t)=\varphi_{\frac{X-\mu}{\sigma}}(t)\), como las
funciones características coinciden se concluye que
\(\frac{X-\mu}{\sigma}\thicksim N(0,1)\).

\begin{teor}
Si $Y\thicksim N(0,1)$ entonces $\sigma Y+\mu \thicksim N(\mu,\sigma)$.
\end{teor}

Calculemos la función característica de la variable \(\sigma Y+\mu\),
\begin{eqnarray}\label{2.1}
\varphi_{\sigma Y+\mu}(t) & = & E\left[e^{it(\sigma Y+\mu)}\right]\nonumber\\
& = & E\left[e^{it\sigma Y+it\mu}\right]\nonumber\\
& = & e^{it\mu}E\left[e^{it\sigma Y}\right]\nonumber\\
& = & e^{it\mu}\int_{-\infty}^{\infty}e^{it\sigma y}\frac{1}{\sqrt{2\pi}}e^{\frac{-y^{2}}{2}}dy\nonumber\\
& = & e^{it\mu}\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{1}{2}(y^{2}-2yit\sigma) }dy.
\end{eqnarray}

Observemos que, \begin{eqnarray}\label{2.2}
y^{2}-2yit\sigma & = & (y-it\sigma)^{2}-(it\sigma)^{2}\nonumber\\
& = & (y-it\sigma)^{2}+t^{2}\sigma^{2}.
\end{eqnarray}

Sustituyendo, (\ref{2.2}) en (\ref{2.1}) resulta
\begin{eqnarray}\label{2.3}
\varphi_{\sigma Y+\mu}(t) & = & e^{it\mu}\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{1}{2}((y-it\sigma)^{2}+t^{2}\sigma^{2}) }dy\nonumber\\
& = & e^{it\mu}e^{-\frac{1}{2}t^{2}\sigma^{2}}\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{1}{2}(y-it\sigma)^{2} }dy
\end{eqnarray}

Tomando \(u=y-it\sigma\Longrightarrow du=dy\), se tiene que \[
\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{1}{2}(y-it\sigma)^{2} }dy=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{u^{2} }{2}}du,
\] entonces \(U\thicksim N(0,1)\), por lo tanto, \[
\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{1}{2}(y-it\sigma)^{2} }dy=1
\]

sustituyendo esto ultimo en (\ref{2.3}), resulta, \[ 
\varphi_{\sigma Y+\mu}(t)=e^{it\mu}e^{-\frac{1}{2}t^{2}\sigma^{2}}=e^{it\mu-\frac{t^{2}\sigma^{2}}{2}}.
\] Sea \(Z\) una variable aleatoria tal que \(Z\thicksim N(\mu,\sigma)\)
sabemos que, \[ 
\varphi_{Z}(t)=e^{it\mu-\frac{t^{2}\sigma^{2}}{2}}.
\] De estas dos ultimas igualdades se sigue que, \[ 
\varphi_{Z}(t)=\varphi_{\sigma Y+\mu}(t).
\] Dado que tienen iguales funciones características se concluye que, \[
\sigma Y+\mu\thicksim N(\mu,\sigma)
\]

\begin{teor}
Si $X\thicksim N(\mu_{1},\sigma_{1}^{2})$, $Y\thicksim N(\mu_{2},\sigma_{2}^{2})$ además 
$X$ y $Y$ son independientes entonces $X+Y\thicksim N(\mu_{1}+\mu_{2},\sigma_{1}^{2}+\sigma_{2}^{2})$.
\end{teor}

Por definición, se tiene que, \begin{eqnarray}\label{3.1}
\varphi_{X+Y}(t) & = & E[e^{it(X+Y)}]\nonumber\\
& = & E[e^{itX}e^{itY}]\text{ por ser independientes, del ejercicio 4}\nonumber\\
& = & E[e^{itX}]E[e^{itY}]\nonumber\\
& = &  \varphi_{X}(t) \varphi_{Y}(t).
\end{eqnarray}

Por otro lado, sea \(Z\) una variables aleatoria tal que,
\(Z\thicksim N(\mu_{1}+\mu_{2},\sigma_{1}^{2}+\sigma_{2}^{2})\), sabemos
que la función característica de \(Z\), esta dada por,

\begin{eqnarray*}
\varphi_{Z}(t) & = & e^{it(\mu_{1}+\mu_{2})-\frac{t^{2}}{2}(\sigma_{1}^{2}+\sigma_{2}^{2})}\nonumber\\
& = & e^{it\mu_{1}-\frac{t^{2}\sigma_{1}^{2}}{2}+it\mu_{2}-\frac{t^{2}\sigma_{2}^{2}}{2}}\nonumber\\
& = & e^{it\mu_{1}-\frac{t^{2}\sigma_{1}^{2}}{2}}e^{it\mu_{2}-\frac{t^{2}\sigma_{2}^{2}}{2}}\\
& = &  \varphi_{X}(t) \varphi_{Y}(t),
\end{eqnarray*} entonces, de esta ultima igualdad y de (\ref{3.1}) se
sigue que, \[
\varphi_{Z}(t)= \varphi_{X+Y}(t).
\]

Como las funciones características coinciden se sigue que,
\(X+Y\thicksim N(\mu_{1}+\mu_{2},\sigma_{1}^{2}+\sigma_{2}^{2})\).

\begin{teor}
Si $X$, $Y$ son variables aleatorias normales entonces $X$, $Y$ son independientes si y solo si $E(XY)=E(X)E(Y)$.
\end{teor}

Primero recordemos que \[
E\left(XY\right)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}xyf_{XY}\left(x,y\right)\mathrm{d}x\mathrm{d}y
\]

Como \(X,Y\) son independientes, sabemos que \[
f_{XY}\left(x,y\right)=f_{X}\left(x\right)f_{Y}\left(y\right)
\]

Entonces

\begin{align*}
E\left(XY\right) & =\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}xyf_{XY}\left(x,y\right)\mathrm{d}x\mathrm{d}y\\
& =\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}xyf_{X}\left(x\right)f_{y}\left(y\right)\mathrm{d}x\mathrm{d}y\\
& =\left(\int_{-\infty}^{\infty}xf_{X}\left(x\right)\mathrm{d}x\right)\left(\int_{-\infty}^{\infty}yf_{y}\left(y\right)\mathrm{d}y\right)\\
& =E\left(X\right)E\left(Y\right)
\end{align*}

Teorema 5.1 (Desigualdad de Chebyshev): Sea \(X\) una variable aleatoria
con esperanza \(\mu=E(X)\) y sea \(\varepsilon>0\). Entonces
\[P(|X-\mu|\geq\varepsilon)\leq\frac{Var(X)}{\varepsilon^{2}}\]

Sea \(Y=\left|X-\mu\right|\), observemos que \(Y\) es positiva, así por
la desigualdad de Markov y dado que
\(\mathcal{P}\left[\left|X-\mu\right|\geq\epsilon\right] =\mathcal{P}\left[\left|X-\mu\right|^{2}\geq\epsilon^{2}\right]\),
se cumple que

\begin{align*}
\mathcal{P}\left[\left|X-\mu\right|\geq\epsilon\right] & =\mathcal{P}\left[\left|X-\mu\right|^{2}\geq\epsilon^{2}\right]\\
& \leq\dfrac{E\left[\left(X-\mu\right)^{2}\right]}{\epsilon^{2}}=\dfrac{\text{Var}\left[X\right]}{\epsilon^{2}}
\end{align*}

Teorema 5.2 (Ley de los grandes números): Sean
\(X_{1},X_{2},\dots, X_{n}\) procesos de ensayos independientes, con
esperanza finita \(\mu=E(X_{j})\) y varianza finita
\(\sigma^{2}=Var(X_{j})\). Sean \(S_{n}=X_{1}+X_{2}+\ldots+X_{n}\).
Entonces para cada \(\epsilon>0\).

\[
\mathcal{P}\left[\left|\dfrac{S_{n}}{n}-\mu\right|\geq\epsilon\right]\to0
\]

Observemos que \begin{align*}
\text{Var}\left[\dfrac{S_{n}}{n}-\mu\right] & =\dfrac{1}{n^{2}}\text{Var}\left(S_{n}\right)\\
& =\dfrac{1}{n^{2}}\sum_{i=1}^{n}\text{Var}\left(X_{i}\right),\text{ por ser iid}\\
& =\dfrac{\sigma^{2}}{n}
\end{align*}

Entonces, por el Teorema 5.1, \[
\mathcal{P}\left[\left|\dfrac{S_{n}}{n}-\mu\right|\geq\epsilon\right]\leq\dfrac{\sigma^{2}}{n\epsilon},
\] así, tomando el limite cuando \(n\to\infty\) \[
\dfrac{\sigma^{2}}{n\epsilon}\to0.
\]

Entonces \[
\mathcal{P}\left[\left|\dfrac{S_{n}}{n}-\mu\right|\geq\epsilon\right]\to0
\]

Teorema 5.3 (de Limite Central):

Sea \(\left\{ X_{i}\right\} _{i=1}^{\infty}\) una secuencia de v.a.i.id
con media \(a\) y varianza \(b^{2}\). Entonces para doo
\(\alpha,\beta\in\mathbb{R}\), con \(\alpha<\beta\), entonces \[
\mathcal{P}\left(\lim_{M\to\infty}\alpha\le\dfrac{{\displaystyle \sum_{i=1}^{M}}X_{i}-Ma}{\sqrt{M}b}\leq\beta\right)=\dfrac{1}{\sqrt{2\pi}}\int_{\alpha}^{\beta}e^{\left(-\dfrac{1}{2}x^{2}\right)}\mathrm{d}x
\]

Definamos a \[
S_{M}={\displaystyle \sum_{i=1}^{M}}\left[X_{i}-a\right],
\] y \[
Y_{M}=\dfrac{S_{M}}{\sqrt{M}b}.
\] Sea \(\varphi_{Y_{M}}\) la función generadora de momentos de
\(Y_{M}\) y \(\varphi\) la función generadora de momentos de la
distribución normal estándar, demostraremos que
\(\varphi_{Y_{M}}\to\varphi\).

Por definición, \begin{align*}
\varphi_{Y_{M}}\left(t\right) & =E\left[\exp\left(t\dfrac{S_{M}}{\sqrt{Mb}}\right)\right]\\
& =\varphi_{S_M}\left(\dfrac{t}{\sqrt{M}b}\right)\\
& =\left[\varphi_{\left(X_{1}-a\right)}\left(\dfrac{t}{\sqrt{M}b}\right)\right]^{M} \text{ ya que, las}X_{i}\text{ son i.i.d}\\
& =\left[E\left[\exp\left(\dfrac{t}{b\sqrt{M}}\left(X_{1}-a\right)\right)\right]\right]
\end{align*}

Recordando la serie de Taylor \begin{align*}
\varphi_{M}\left(t\right) & =\left[\sum_{i=0}^{\infty}\dfrac{E\left[\left(\dfrac{t}{b\sqrt{M}}\left(X_{1}-a\right)\right)^{i}\right]}{i!}\right]^{M}\\
& =\left[1+\dfrac{1}{2}\left(\dfrac{t}{b\sqrt{M}}\right)^{2}E\left[\left(X_{1}-a\right)^{2}\right]+\epsilon\left(3\right)\right]^{M}\\
& =\left[1+\dfrac{1}{M}\dfrac{t^{2}}{2}+\epsilon\left(3\right)\right]^{M},
\end{align*}

donde \begin{align*}
\epsilon\left(3\right) & =\sum_{i=3}^{\infty}\dfrac{E\left[\left(\dfrac{t}{b\sqrt{M}}\left(X_{1}-a\right)\right)^{i}\right]}{i!},
\end{align*}

Sea \(s=\dfrac{t}{b\sqrt{M}},\) entonces \(s\to0,t\to0\) \[
\epsilon\left(3\right)=\sum_{i=3}^{\infty}\dfrac{E\left[\left(X_{1}-a\right)^{i}\right]s^{i}}{i!}
\]

Notemos que, si \(\varphi_{1}\) existe. Entonces \[
\dfrac{\epsilon\left(3\right)}{s^{2}}=\sum_{i=3}^{\infty}\dfrac{E\left[\left(X_{1}-a\right)^{i}\right]s^{i-2}}{i!}\to0,s\to0.
\] .

Además \(s\to0\) cuando \(M\to\infty\). \[
\Rightarrow\varphi_{M}\left(t\right)=\left[1+\dfrac{1}{M}\left[\dfrac{t^{2}}{2}+M\epsilon\left(3\right)\right]\right]^{M},
\]

Entonces
\(\epsilon\left(3\right)s^{-2}=Me\left(3\right)b^{2}t^{-2}\to0\). Como
\(b,t\) estan fijas. \[
M\epsilon\left(3\right)\to0,M\to\infty,
\]

por lo tanto \begin{align*}
\dfrac{t^{2}}{2}+M\epsilon\left(3\right) & \to\dfrac{t^{2}}{2},M\to\infty\\
\left[1+\dfrac{1}{M}\left[\dfrac{t^{2}}{2}+M\epsilon\left(3\right)\right]\right]^{M} & \to\exp\left(t^{2}\right),M\to\infty\\
\lim_{M\to\infty}\varphi_{M}\left(t\right) & =\exp\left(t^{2}\right)=\varphi\left(t\right),
\end{align*}

la función generadora de momentos de la distribución normal estándar.
Por lo tanto \[
F_{M}\left(x\right)\to F_{N\left(0,1\right)}\left(x\right)
\]

\begin{align*}
F_{M}\left(b\right)-F_{M}\left(a\right) & \to F_{N}\left(b\right)-F_{N}\left(a\right)\\
\mathcal{P}\left(\lim_{M\to\infty}\alpha\le\dfrac{{\displaystyle \sum_{i=1}^{M}}X_{i}-Ma}{\sqrt{M}b}\leq\beta\right) & =\dfrac{1}{\sqrt{2\pi}}\int_{\alpha}^{\beta}\exp\left(-\dfrac{1}{2}x^{2}\right)\mathrm{d}x
\end{align*}

Teorema 5.4:Sea \(\left\{ X_{i}\right\} _{i=1}^{\infty}\) una sucesión
de v.a.i.i.d con media \(a\). Entonces \[
\mathcal{P}\left[\lim_{M\to\infty}\dfrac{1}{M}\sum_{i=1}^{M}X_{i}=a\right]=1.
\]

Esto es similar a decir que \[
\lim_{M\to\infty}\dfrac{1}{M}\sum_{i=1}^{M}X_{i}\stackrel{\text{c.s}}{=}a
\]

Sin perdida de generalidad, diremos que \(X_{i}\geq0,\forall i\).
Definamos \[
Y_{n}=X_{n}I_{\left[\left|X_{n}\right|\leq n\right]},Q_{n}=\sum_{i=1}^{n}Y_{i}
\]

Por la desigualdad de \begin{align*}
\sum_{n=1}^{\infty}\mathcal{P}\left[\left|\dfrac{Q_{n}-E\left[Q_{n}\right]}{n}\right|\geq\epsilon\right] & \leq\sum_{n=1}^{\infty}\dfrac{\text{Var}\left(Q_{n}\right)}{\epsilon^{2}n^{2}}=\sum_{n=1}^{\infty}\dfrac{1}{\epsilon^{2}n^{2}}\sum_{i=1}^{n}\text{Var}\left(Y_{i}\right)\\
& \leq\sum_{n=1}^{\infty}\dfrac{E\left(Y_{n}^{2}\right)}{\epsilon^{2}n^{2}}=\sum_{n=1}^{\infty}\dfrac{1}{\epsilon^{2}n^{2}}\int_{0}^{n}x^{2}\mathrm{d}F\\
& \leq\sum_{n=1}^{\infty}\dfrac{1}{\epsilon^{2}}\int_{0}^{n}x\mathrm{d}F<\infty,
\end{align*}

donde \(F\) es la función de distribución de \(X_{i}\). Luego \[
E\left[X_{1}\right]=\lim_{n\to\infty}\int_{0}^{n}x\mathrm{d}F=\lim_{n\to\infty}E\left[Y_{n}\right]=\lim_{n\to\infty}\dfrac{E\left[Q_{n}\right]}{n}.
\]

Entonces, por el Lema de Borel Canteli.
\(\mathcal{\mathcal{P}}\left[\limsup\left(\left|\dfrac{Q_{n}-E\left[Q_{n}\right]}{n}\right|\geq\epsilon\right)\right]=0\)

\[
\lim_{n\to\infty}\dfrac{Q_{n}}{n}=E\left[X_{1}\right],\text{c.s}
\]

Ahora, calcularemos la siguiente probabilidad \[
\sum_{i=1}^{\infty}\mathcal{P}\left[X_{i}\neq Y_{i}\right]=\sum_{i=1}^{\infty}\mathcal{P}\left[X_{i}>n\right]
\]

como \(E\left[X_{i}\right]<\infty\) y \(X_{i}\) son v.a.i.i.d.

\[
\sum_{i=1}^{\infty}\mathcal{P}\left[X_{i}>n\right]\leq E\left[X_{1}\right]<\infty
\]

De nuevo, por el Lema de Borel Cantelli. \[
\mathcal{P}\left[\limsup\left[X_{i}\neq Y_{i}\right]\right]=0,\forall i
\]

Entonces \begin{align*}
X_{i} & =Y_{i},\text{c.s}\\
\Rightarrow & \dfrac{1}{M}\sum_{i=1}^{M}X_{i}\to E\left[X_{1}\right]=\mu.\text{ c.s}
\end{align*}

\bookmarksetup{startatroot}

\hypertarget{tarea-4}{%
\chapter{Tarea 4}\label{tarea-4}}

\hypertarget{ejercicio-1}{%
\section{Ejercicio 1}\label{ejercicio-1}}

Sea \(W(t)\) un movimiento Browniano estándar en \([0,T]\). Pruebe que
para cualquier \(c>0\) fijo, \[
V(t) = \dfrac{1}{c} W(c^2 t)
\]

es un movimiento Browniano sobre \([0,T]\).

\hypertarget{demostraciuxf3n}{%
\subsection{Demostración}\label{demostraciuxf3n}}

Veamos que \(V\) cumple las propiedades del movimiento Browniano.

\hypertarget{propiedad-1-que-comience-en-0}{%
\subsubsection{Propiedad 1 (Que comience en
0)}\label{propiedad-1-que-comience-en-0}}

Se tiene que, \(V(0) = \dfrac{1}{c} W (c^2\cdot0)=0\).

\hypertarget{propiedad-2-incrementos-independientes}{%
\subsubsection{Propiedad 2 (Incrementos
Independientes)}\label{propiedad-2-incrementos-independientes}}

Sean \(s<t<u<v\), por definición de \(V\), se tiene que, \[
E[\left(V(t)-V(s)\right)\left(V(v)-V(u)\right)]=\dfrac{1}{c^2}E[\left(W(c^2 t)-W(c^2 s)\right)\left(W(c^2 v)-W(c^2 u)\right)]
\]

Dado que \(W\) tiene incrementos independientes, se cumple que.
\begin{align*}
\dfrac{1}{c^{2}}E\left[\left(W(c^{2}t)-W(c^{2}s)\right)\left(W(c^{2}v)-W(c^{2}u)\right)\right] & =\dfrac{1}{c^{2}}E\left[\left(W(c^{2}t)-W(c^{2}s)\right)\right]E\left[\left(W(c^{2}v)-W(c^{2}u)\right)\right]
\end{align*}

Entonces \(V\) tiene incrementos independientes.

\hypertarget{propiedad-3-incrementos-estacionarios}{%
\subsubsection{Propiedad 3 (Incrementos
estacionarios)}\label{propiedad-3-incrementos-estacionarios}}

Sea \(s<t\). \[
V(t)-V(s)=\dfrac{1}{c}\left[W(c^2 t) - W(c^2 s)\right]
\]

Por las propiedades de la definicion del movimiento Browniano.

\begin{align*}
E\left[V(t)-V(s)\right] & =\dfrac{1}{c}E\left[W(c^{2}t)-W(c^{2}s)\right]=0\\
\text{Var}\left[V(t)-V(s)\right] & =\dfrac{1}{c^{2}}\text{Var}\left[W(c^{2}t)-W(c^{2}s)\right]=\dfrac{1}{c^{2}}\left(c^{2}\left(t-s\right)\right)=t-s
\end{align*}

Entonces \(V\) tiene incrementos estacionarios.

Con todo lo anterior se concluye que, \(V\) es un movimiento browniano.

\hypertarget{ejercicio-2}{%
\section{Ejercicio 2}\label{ejercicio-2}}

Hacer un script para ilustrar la propiedad de escalado del movimiento
Browniano para el caso de \(c = \dfrac{1}{5}\). Estar seguro que usa el
mismo camino browniano discretizado en cada subplot.

\begin{codelisting}

\caption{\texttt{Browniano escalado, con c=1/5.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\NormalTok{prng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{123456789}\NormalTok{)}
\NormalTok{T }\OperatorTok{=} \DecValTok{1}  
\NormalTok{n}\OperatorTok{=} \DecValTok{100}  
\NormalTok{dt }\OperatorTok{=} \DecValTok{1} \OperatorTok{/}\NormalTok{ (n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}
\NormalTok{dw }\OperatorTok{=}\NormalTok{ np.sqrt(dt) }\OperatorTok{*}\NormalTok{ prng.standard\_normal(n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{) }
\NormalTok{w }\OperatorTok{=}\NormalTok{ np.concatenate(([}\DecValTok{0}\NormalTok{],dw.cumsum()))}

\NormalTok{time }\OperatorTok{=}\NormalTok{ np.linspace(}\DecValTok{0}\NormalTok{,T, n)}
\NormalTok{c }\OperatorTok{=} \FloatTok{0.2}  \CommentTok{\# 1/5}
\NormalTok{c\_time }\OperatorTok{=}\NormalTok{ c}\OperatorTok{**}\DecValTok{2} \OperatorTok{*}\NormalTok{ time  }
\NormalTok{c\_w }\OperatorTok{=}\NormalTok{ c}\OperatorTok{**}\NormalTok{(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{) }\OperatorTok{*}\NormalTok{ w  }

\NormalTok{fig, browniano\_escalado }\OperatorTok{=}\NormalTok{ plt.subplots(}\DecValTok{2}\NormalTok{)}
\NormalTok{browniano\_escalado[}\DecValTok{0}\NormalTok{].plot(time, w)}
\NormalTok{browniano\_escalado[}\DecValTok{1}\NormalTok{].plot(c\_time, c\_w)}
\NormalTok{browniano\_escalado[}\DecValTok{0}\NormalTok{].set\_title(}\StringTok{\textquotesingle{}Movimiento browniano\textquotesingle{}}\NormalTok{)}
\NormalTok{browniano\_escalado[}\DecValTok{1}\NormalTok{].set\_title(}\StringTok{\textquotesingle{}Moviemiento browniano escalado\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{figure}

{\centering \includegraphics{Figure_T4-1.png}

}

\caption{Figura 1}

\end{figure}

\hypertarget{ejercicio-3}{%
\section{Ejercicio 3}\label{ejercicio-3}}

Modifique el script \texttt{half\_brownian\_refinement.py} encapsulando
el código en una función. Esta función deberá recibir el extremo derecho
del intervalo \([0, T]\) y el número de incrementos \(N\) de un camino
browniano base. El propósito es calcular los incrementos de relleno de
una refinamiento con \(2N\) incrementos.

\begin{codelisting}

\caption{\texttt{Browniano refinado, con refinamiento 2N.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\NormalTok{prng }\OperatorTok{=}\NormalTok{ np.random.RandomState(}\DecValTok{123456789}\NormalTok{)}

\KeywordTok{def}\NormalTok{ refined\_brownian\_2n(T,L):}
\NormalTok{    dt }\OperatorTok{=}\NormalTok{ T }\OperatorTok{/}\NormalTok{ L}
\NormalTok{    W }\OperatorTok{=}\NormalTok{ np.zeros(L }\OperatorTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{    W\_refined }\OperatorTok{=}\NormalTok{ np.zeros(}\DecValTok{2} \OperatorTok{*}\NormalTok{ L }\OperatorTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{    xi }\OperatorTok{=}\NormalTok{ np.sqrt(dt) }\OperatorTok{*}\NormalTok{ prng.normal(size}\OperatorTok{=}\NormalTok{L)}
\NormalTok{    xi\_half }\OperatorTok{=}\NormalTok{ np.sqrt(}\FloatTok{0.5} \OperatorTok{*}\NormalTok{ dt) }\OperatorTok{*}\NormalTok{ prng.normal(size}\OperatorTok{=}\NormalTok{L)}
\NormalTok{    W[}\DecValTok{1}\NormalTok{:] }\OperatorTok{=}\NormalTok{ xi.cumsum()}
\NormalTok{    W\_ }\OperatorTok{=}\NormalTok{ np.roll(W, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{    W\_half }\OperatorTok{=} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ (W }\OperatorTok{+}\NormalTok{ W\_)}
\NormalTok{    W\_half }\OperatorTok{=}\NormalTok{ np.delete(W\_half, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\NormalTok{ xi\_half}
\NormalTok{    W\_refined[}\DecValTok{1}\NormalTok{::}\DecValTok{2}\NormalTok{] }\OperatorTok{=}\NormalTok{ W\_half}
\NormalTok{    W\_refined[}\DecValTok{2}\NormalTok{::}\DecValTok{2}\NormalTok{] }\OperatorTok{=}\NormalTok{ W[}\DecValTok{1}\NormalTok{:]}
\NormalTok{    t }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{0}\NormalTok{, T }\OperatorTok{+}\NormalTok{ dt, dt)}
\NormalTok{    t\_half }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{0}\NormalTok{, T }\OperatorTok{+} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ dt, }\FloatTok{0.5} \OperatorTok{*}\NormalTok{ dt)}
    \ControlFlowTok{return}\NormalTok{ t,t\_half,W, W\_refined}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\hypertarget{ejercicio-4}{%
\section{Ejercicio 4}\label{ejercicio-4}}

En un script separado, incluya la función de arriba y grafique una
figura con la trayectoria del browniano con 100 incrementos y muestre su
refinamiento correspondiente.

\begin{codelisting}

\caption{\texttt{Browniano refinado, con refinamiento 2N y 100 incrementos.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ h\_b\_r }\ImportTok{as}\NormalTok{ hbr}

\NormalTok{a, b, c, d }\OperatorTok{=}\NormalTok{ hbr.refined\_brownian\_2n(}\DecValTok{1}\NormalTok{, }\DecValTok{100}\NormalTok{)}

\NormalTok{plt.plot(a, c, }\StringTok{\textquotesingle{}r{-}+\textquotesingle{}}\NormalTok{)}
\NormalTok{plt.plot(}
\NormalTok{    b,}
\NormalTok{    d,}
    \StringTok{\textquotesingle{}g*{-}{-}\textquotesingle{}}\NormalTok{,}
    \CommentTok{\# alpha = transparecia}
\NormalTok{    )}
\NormalTok{plt.show()}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{figure}

{\centering \includegraphics{Figure_2_T4.png}

}

\caption{Figura 2}

\end{figure}

\bookmarksetup{startatroot}

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-knuth84}{}}%
Knuth, Donald E. 1984. {``Literate Programming.''} \emph{Comput. J.} 27
(2): 97--111. \url{https://doi.org/10.1093/comjnl/27.2.97}.

\end{CSLReferences}



\end{document}
